{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063e37eb",
   "metadata": {},
   "source": [
    "# Creating Eigenfaces & Recognizing Faces from training set using cv2 functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c133bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import imageio\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf9c5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (\"Loading Trained model\")\n",
    "# # Load the trained eigenfaces model\n",
    "# model = cv2.face.EigenFaceRecognizer_create()\n",
    "# model.read('eigenfaces_model.xml')\n",
    "\n",
    "data = np.genfromtxt('MeanAndFaces.csv', delimiter=',')\n",
    "mean = data[0]\n",
    "eigenmatrix = data[1:]\n",
    "data = np.genfromtxt('ACR.csv', delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef4ee88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "labels = np.array([0,0,0,0,0,1,1,1,1,1,2,2,2,2,2])\n",
    "\n",
    "# Create a KNN classifier with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "knn.fit(data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a78b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video, 0 for webcam, str for path to video\n",
    "video = cv2.VideoCapture(0)\n",
    "# video = cv2.VideoCapture('test_clip.mp4')\n",
    "\n",
    "# Exit if video not opened.\n",
    "if not video.isOpened():\n",
    "    print('Could not open video!')\n",
    "    sys.exit()\n",
    "\n",
    "# Tracker Variables\n",
    "tracker = None\n",
    "roi = (0, 0, 0, 0)\n",
    "# -1 for not tracking, 0 for init tracking, 1 for update tracking\n",
    "tracking_flag = -1\n",
    "\n",
    "# Loop simulate Camera Preview Callback\n",
    "while True:\n",
    "\n",
    "    # Capture user Key Press to simulate App Control\n",
    "    key = cv2.waitKey(1) & 0xff\n",
    "    # User Press Enter\n",
    "    if key == 13:\n",
    "        # Not tracking\n",
    "        if tracking_flag == -1:\n",
    "            # Pause and let user select ROI\n",
    "#             roi = cv2.selectROI(frame, False) # Manual Setting of ROI in seperate window\n",
    "#             print(\"ROI: \", roi)\n",
    "            print(\"Frame Shape: \", frame.shape) # Frame Shape:  (480, 640, 3)\n",
    "            \n",
    "            # Init tracking\n",
    "            tracking_flag = 0\n",
    "        # Is tracking\n",
    "        if tracking_flag == 1:\n",
    "            # Reset ROI\n",
    "            roi = (0, 0, 0, 0)\n",
    "            # Clear Tracker\n",
    "            tracker.clear()\n",
    "            # Stop tracking\n",
    "            tracking_flag = -1\n",
    "    # User Press ESC\n",
    "    elif key == 27:\n",
    "        break\n",
    "    \n",
    "    # Start timer\n",
    "    start = cv2.getTickCount()\n",
    "\n",
    "    # Read Next frame.\n",
    "    read_success, frame = video.read()\n",
    "    if not read_success:\n",
    "        print('Cannot read video file!')\n",
    "        sys.exit()\n",
    "\n",
    "    if tracking_flag == -1:\n",
    "\n",
    "        # Display Text\n",
    "        cv2.putText(frame, \"Press ENTER to select ROI!\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        \n",
    "        # Get frame dimensions\n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        w = 178 # The width of the selected ROI.\n",
    "        h = 218 # The height of the selected ROI.            \n",
    "        x = int(width/2 - w/2) # The x-coordinate of the top-left corner of the selected region of interest (ROI).\n",
    "        y = int(height/2 - h/2) # The y-coordinate of the top-left corner of the selected ROI.\n",
    "\n",
    "        # (218 # of rows, 178 # of columns)\n",
    "\n",
    "        roi = (x, y, w, h)\n",
    "\n",
    "        # Draw ROI Rectangle\n",
    "        p1 = (int(roi[0]), int(roi[1]))\n",
    "        p2 = (int(roi[0] + roi[2]), int(roi[1] + roi[3]))\n",
    "        cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
    "\n",
    "\n",
    "    elif tracking_flag == 0:\n",
    "\n",
    "        # Initialize KCF Tracker and Start Tracking\n",
    "        # 1. Create a KCF Tracker\n",
    "        # 2. Initialize KCF Tracker with grayscale image and ROI\n",
    "        # 3. Modify tracking flag to start tracking\n",
    "        # Your code starts here\n",
    "        #cv2.getTickFrequency()\n",
    "        # print(\"ROI: \", roi) # ROI:  (240, 320, 178, 218)\n",
    "        tracker = cv2.TrackerKCF_create()\n",
    "        status = tracker.init(frame,roi)\n",
    "        \n",
    "        tracking_flag = 1\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Update tracking result is succeed\n",
    "        # If failed, print text \"Tracking failure occurred!\" at top left corner of the frame\n",
    "        # Calculate and display \"FPS@fps_value\" at top right corner of the frame\n",
    "        # Your code starts here\n",
    "        read_success, roi = tracker.update(frame)\n",
    "        \n",
    "        # Crop the frame\n",
    "        cropped_frame = frame[roi[0]:roi[0]+roi[2], roi[1]:roi[1]+roi[3]]\n",
    "\n",
    "        cropped_resized_frame = Image.fromarray(cropped_frame.astype('uint8'))\n",
    "\n",
    "        grayscale_image_cropped = cropped_resized_frame.convert('L')\n",
    "\n",
    "        # Set the new size (half of original size in this example)\n",
    "        new_size = (178, 218)\n",
    "\n",
    "        # Resize the image using the Lanczos filter (you can use other filters too)\n",
    "        resized_cropped_image = grayscale_image_cropped.resize(new_size, resample=Image.LANCZOS)\n",
    "\n",
    "        resize_crop_img = np.array(resized_cropped_image)\n",
    "\n",
    "        if read_success == False:\n",
    "            cv2.putText(frame, \"Tracking failure occured\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        else:\n",
    "            # Load the image to be recognized\n",
    "            # image = cv2.imread(frame, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # print (\"Resizing Frame\")\n",
    "            # Resize the image to the same size as the training images\n",
    "            # image = cv2.resize(frame, (720, 1280))\n",
    "            \n",
    "            # Convert the image to grayscale\n",
    "#             gray_frame = cv2.cvtColor(resized_cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            flattened_gray = np.ndarray.flatten(resize_crop_img) - mean            \n",
    "            \n",
    "            \n",
    "            finaldata = eigenmatrix @ flattened_gray\n",
    "            \n",
    "            \n",
    "            \n",
    "            # print (\"Computing Eigenface confidence\")\n",
    "            # Compute the eigenface coefficients for the image\n",
    "            # The predict function returns the predicted label and the confidence score\n",
    "#             label, confidence = model.predict(cropped_frame)\n",
    "            \n",
    "            \n",
    "\n",
    "        fps_value = int(cv2.getTickFrequency()/(cv2.getTickCount() - start))\n",
    "        cv2.putText(frame, \"FPS@\"+str(fps_value), (500, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "#         cv2.putText(frame, \"Predicted Label:\"+str(label), (100, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "#         cv2.putText(frame, \"Confidence Score:\"+str(confidence), (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        \n",
    "\n",
    "        label = knn.predict(finaldata.reshape(1,-1))\n",
    "    \n",
    "        if (label == 0):\n",
    "            cv2.putText(frame, \"Predicted label: Aahan\", (100, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        elif (label == 1):\n",
    "            cv2.putText(frame, \"Predicted label: Chaz\", (100, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        elif (label == 2):\n",
    "            cv2.putText(frame, \"Predicted label: Rutvik\", (100, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        \n",
    "#         cv2.putText(frame, \"Confidence score: {}\".format(confidence), (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Draw ROI Rectangle\n",
    "    p1 = (int(roi[0]), int(roi[1]))\n",
    "    p2 = (int(roi[0] + roi[2]), int(roi[1] + roi[3]))\n",
    "    cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
    "    # Display result\n",
    "    cv2.imshow(\"ECE420 Lab7\", frame)\n",
    "    \n",
    "\n",
    "# # Print the predicted label and confidence score\n",
    "# print('Predicted label: {}'.format(label))\n",
    "# print('Confidence score: {}'.format(confidence))\n",
    "# print(\"0 = Aahan; 1 = Chaz; 2 = Rutvik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f6249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

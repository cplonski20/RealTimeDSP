{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80d65d3",
   "metadata": {},
   "source": [
    "# Creating Eigenfaces & Recognizing Faces from training set using cv2 functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c133bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import imageio\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e91b307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_face_dataset(dataset_path):\n",
    "#     faces = []\n",
    "#     labels = []\n",
    "\n",
    "#     # Get a list of subdirectories in the dataset path\n",
    "#     person_dirs = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "\n",
    "#     # Loop through each person's directory and read their face images\n",
    "#     for i, person_dir in enumerate(person_dirs):\n",
    "#         # Get a list of image files in the person's directory\n",
    "#         image_files = [os.path.join(dataset_path, person_dir, f) for f in os.listdir(os.path.join(dataset_path, person_dir)) if os.path.isfile(os.path.join(dataset_path, person_dir, f))]\n",
    "\n",
    "#         # Read each image file and append to the faces list\n",
    "#         for image_file in image_files:\n",
    "#             image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "#             # print (image.shape)\n",
    "#             faces.append(image)\n",
    "\n",
    "#         # Append a label for each face image in this person's directory\n",
    "#         labels.extend([i] * len(image_files))\n",
    "\n",
    "#     # Convert the faces and labels lists to numpy arrays\n",
    "#     faces = np.array(faces)\n",
    "#     labels = np.array(labels)\n",
    "\n",
    "#     return faces, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "836af0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the image file\n",
    "# image = Image.open('./model_training_images/Aahan/aahan.jpg')\n",
    "\n",
    "# # Set the new size (half of original size in this example)\n",
    "# new_size = (218, 178)\n",
    "\n",
    "# # Resize the image using the Lanczos filter (you can use other filters too)\n",
    "# resized_image = image.resize(new_size, resample=Image.LANCZOS)\n",
    "\n",
    "# print(resized_image.size)\n",
    "# # Save the resized image to a file\n",
    "# resized_image.save(\"resized_aahan.jpg\")\n",
    "\n",
    "# # Open the image file\n",
    "# image = Image.open('./model_training_images/Chaz/chaz.jpg')\n",
    "\n",
    "# # Set the new size (half of original size in this example)\n",
    "# new_size = (218, 178)\n",
    "\n",
    "# # Resize the image using the Lanczos filter (you can use other filters too)\n",
    "# resized_image = image.resize(new_size, resample=Image.LANCZOS)\n",
    "\n",
    "# print(resized_image.size)\n",
    "# # Save the resized image to a file\n",
    "# resized_image.save(\"resized_chaz.jpg\")\n",
    "\n",
    "# # Open the image file\n",
    "# image = Image.open('./model_training_images/Rutvik/rutvik.jpg')\n",
    "\n",
    "# # Set the new size (half of original size in this example)\n",
    "# new_size = (218, 178)\n",
    "\n",
    "# # Resize the image using the Lanczos filter (you can use other filters too)\n",
    "# resized_image = image.resize(new_size, resample=Image.LANCZOS)\n",
    "\n",
    "# print(resized_image.size)\n",
    "# # Save the resized image to a file\n",
    "# resized_image.save(\"resized_rutvik.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ec0f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (\"Loading given images\")\n",
    "# # Load the face dataset and corresponding labels\n",
    "# faces, labels = load_face_dataset(\"model_training_images\")\n",
    "\n",
    "# # Train the eigenfaces model using the face dataset and labels\n",
    "# model = cv2.face.EigenFaceRecognizer_create()\n",
    "# model.train(faces, labels)\n",
    "\n",
    "# print (\"Saving trained model\")\n",
    "# # Save the trained model to a file\n",
    "# model.save('eigenfaces_model.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a5f663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Trained model\n"
     ]
    }
   ],
   "source": [
    "print (\"Loading Trained model\")\n",
    "# Load the trained eigenfaces model\n",
    "model = cv2.face.EigenFaceRecognizer_create()\n",
    "model.read('eigenfaces_model.xml')\n",
    "\n",
    "# data = np.genfromtxt('MeanAndFaces.csv', delimiter=',', max_rows = 101)\n",
    "# mean = data[0]\n",
    "# eigenmatrix = data[1:]\n",
    "# data = np.genfromtxt('MeanAndFaces.csv', delimiter=',', skip_header = 101)\n",
    "# aahandata = data[0]\n",
    "# chazdata = data[1]\n",
    "# rudydata = data[2]\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9635664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Shape:  (480, 640, 3)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    149\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFPS@\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(fps_value), (\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m30\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.75\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m#         cv2.putText(frame, \"Predicted Label:\"+str(label), (100, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m#         cv2.putText(frame, \"Confidence Score:\"+str(confidence), (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m         label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(\u001b[43mresults\u001b[49m)\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;28mprint\u001b[39m(results)\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (label \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# Load video, 0 for webcam, str for path to video\n",
    "video = cv2.VideoCapture(0)\n",
    "# video = cv2.VideoCapture('test_clip.mp4')\n",
    "\n",
    "# Exit if video not opened.\n",
    "if not video.isOpened():\n",
    "    print('Could not open video!')\n",
    "    sys.exit()\n",
    "\n",
    "# Tracker Variables\n",
    "tracker = None\n",
    "roi = (0, 0, 0, 0)\n",
    "# -1 for not tracking, 0 for init tracking, 1 for update tracking\n",
    "tracking_flag = -1\n",
    "\n",
    "# Loop simulate Camera Preview Callback\n",
    "while True:\n",
    "\n",
    "    # Capture user Key Press to simulate App Control\n",
    "    key = cv2.waitKey(1) & 0xff\n",
    "    # User Press Enter\n",
    "    if key == 13:\n",
    "        # Not tracking\n",
    "        if tracking_flag == -1:\n",
    "            # Pause and let user select ROI\n",
    "#             roi = cv2.selectROI(frame, False) # Manual Setting of ROI in seperate window\n",
    "#             print(\"ROI: \", roi)\n",
    "            print(\"Frame Shape: \", frame.shape) # Frame Shape:  (480, 640, 3)\n",
    "            \n",
    "            # Init tracking\n",
    "            tracking_flag = 0\n",
    "        # Is tracking\n",
    "        if tracking_flag == 1:\n",
    "            # Reset ROI\n",
    "            roi = (0, 0, 0, 0)\n",
    "            # Clear Tracker\n",
    "            tracker.clear()\n",
    "            # Stop tracking\n",
    "            tracking_flag = -1\n",
    "    # User Press ESC\n",
    "    elif key == 27:\n",
    "        break\n",
    "    \n",
    "    # Start timer\n",
    "    start = cv2.getTickCount()\n",
    "\n",
    "    # Read Next frame.\n",
    "    read_success, frame = video.read()\n",
    "    if not read_success:\n",
    "        print('Cannot read video file!')\n",
    "        sys.exit()\n",
    "\n",
    "    if tracking_flag == -1:\n",
    "\n",
    "        # Display Text\n",
    "        cv2.putText(frame, \"Press ENTER to select ROI!\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        \n",
    "        # Get frame dimensions\n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        w = 178 # The width of the selected ROI.\n",
    "        h = 218 # The height of the selected ROI.            \n",
    "        x = int(width/2 - w/2) # The x-coordinate of the top-left corner of the selected region of interest (ROI).\n",
    "        y = int(height/2 - h/2) # The y-coordinate of the top-left corner of the selected ROI.\n",
    "\n",
    "        # (218 # of rows, 178 # of columns)\n",
    "\n",
    "        roi = (x, y, w, h)\n",
    "\n",
    "        # Draw ROI Rectangle\n",
    "        p1 = (int(roi[0]), int(roi[1]))\n",
    "        p2 = (int(roi[0] + roi[2]), int(roi[1] + roi[3]))\n",
    "        cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
    "\n",
    "\n",
    "    elif tracking_flag == 0:\n",
    "\n",
    "        # Initialize KCF Tracker and Start Tracking\n",
    "        # 1. Create a KCF Tracker\n",
    "        # 2. Initialize KCF Tracker with grayscale image and ROI\n",
    "        # 3. Modify tracking flag to start tracking\n",
    "        # Your code starts here\n",
    "        #cv2.getTickFrequency()\n",
    "        # print(\"ROI: \", roi) # ROI:  (240, 320, 178, 218)\n",
    "        tracker = cv2.TrackerKCF_create()\n",
    "        status = tracker.init(frame,roi)\n",
    "        \n",
    "        tracking_flag = 1\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Update tracking result is succeed\n",
    "        # If failed, print text \"Tracking failure occurred!\" at top left corner of the frame\n",
    "        # Calculate and display \"FPS@fps_value\" at top right corner of the frame\n",
    "        # Your code starts here\n",
    "        read_success, roi = tracker.update(frame)\n",
    "        \n",
    "        # Crop the frame\n",
    "        cropped_frame = frame[roi[0]:roi[0]+roi[2], roi[1]:roi[1]+roi[3]]\n",
    "        \n",
    "        cropped_resized_frame = Image.fromarray(cropped_frame.astype('uint8'))\n",
    "        \n",
    "        grayscale_image_cropped = cropped_resized_frame.convert('L')\n",
    "        \n",
    "        # Set the new size (half of original size in this example)\n",
    "        new_size = (178, 218)\n",
    "\n",
    "        # Resize the image using the Lanczos filter (you can use other filters too)\n",
    "        resized_cropped_image = grayscale_image_cropped.resize(new_size, resample=Image.LANCZOS)\n",
    "        \n",
    "        resize_crop_img = np.array(resized_cropped_image)\n",
    "\n",
    "        if read_success == False:\n",
    "            cv2.putText(frame, \"Tracking failure occured\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        else:\n",
    "            # Load the image to be recognized\n",
    "            # image = cv2.imread(frame, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # print (\"Resizing Frame\")\n",
    "            # Resize the image to the same size as the training images\n",
    "            # image = cv2.resize(frame, (720, 1280))\n",
    "            \n",
    "            # Convert the image to grayscale\n",
    "#             gray_frame = cv2.cvtColor(resized_cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "#             flattened_gray = np.ndarray.flatten(resize_crop_img) - mean            \n",
    "            \n",
    "            # Resize the image\n",
    "            # image = resize(gray_frame, (720, 1280))\n",
    "            # print(image.shape)\n",
    "            \n",
    "#             finaldata = eigenmatrix @ flattened_gray\n",
    "            \n",
    "#             results = np.zeros(3)\n",
    "\n",
    "#             results[0] = np.linalg.norm(aahandata - finaldata)\n",
    "#             results[1] = np.linalg.norm(chazdata - finaldata)\n",
    "#             results[2] = np.linalg.norm(rudydata - finaldata)\n",
    "            \n",
    "            # print (\"Computing Eigenface confidence\")\n",
    "            # Compute the eigenface coefficients for the image\n",
    "            # The predict function returns the predicted label and the confidence score\n",
    "            label, confidence = model.predict(resize_crop_img)\n",
    "            \n",
    "            \n",
    "\n",
    "        fps_value = int(cv2.getTickFrequency()/(cv2.getTickCount() - start))\n",
    "        cv2.putText(frame, \"FPS@\"+str(fps_value), (500, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "#         cv2.putText(frame, \"Predicted Label:\"+str(label), (100, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "#         cv2.putText(frame, \"Confidence Score:\"+str(confidence), (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        \n",
    "#         label = np.argmin(results)\n",
    "#         print(results)\n",
    "    \n",
    "        if (label == 0):\n",
    "            cv2.putText(frame, \"Predicted label: Aahan\", (100, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        elif (label == 1):\n",
    "            cv2.putText(frame, \"Predicted label: Chaz\", (100, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        elif (label == 2):\n",
    "            cv2.putText(frame, \"Predicted label: Rutvik\", (100, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        \n",
    "#         cv2.putText(frame, \"Confidence score: {}\".format(confidence), (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Draw ROI Rectangle\n",
    "    p1 = (int(roi[0]), int(roi[1]))\n",
    "    p2 = (int(roi[0] + roi[2]), int(roi[1] + roi[3]))\n",
    "    cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
    "    # Display result\n",
    "    cv2.imshow(\"ECE420 Lab7\", frame)\n",
    "    \n",
    "\n",
    "# # Print the predicted label and confidence score\n",
    "# print('Predicted label: {}'.format(label))\n",
    "# print('Confidence score: {}'.format(confidence))\n",
    "# print(\"0 = Aahan; 1 = Chaz; 2 = Rutvik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485cb6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48999ad5",
   "metadata": {},
   "source": [
    "# Creating Eigenfaces with slider weights using cv2 functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c9678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary packages.\n",
    "# from __future__ import print_function\n",
    "# import os\n",
    "# import sys\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # Read images from the directory.\n",
    "# def readImages(path):\n",
    "#     print(\"Reading images from \" + path, end = \"...\")\n",
    "\n",
    "#     # Create array of array of images.\n",
    "#     images = []\n",
    "#     # List all files in the directory and read points from text files one by one.\n",
    "#     for filePath in sorted(os.listdir(path)):\n",
    "#         fileExt = os.path.splitext(filePath)[1]\n",
    "#         if fileExt in [\".jpg\", \".jpeg\"]:\n",
    "\n",
    "#             # Add to array of images.\n",
    "#             imagePath = os.path.join(path, filePath)\n",
    "#             im = cv2.imread(imagePath) #, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#             if im is None :\n",
    "#                 print(\"image:{} not read properly\".format(imagePath))\n",
    "#             else :\n",
    "#                 # Convert image to floating point.\n",
    "#                 im = np.float32(im)/255.0\n",
    "#                 # Add image to list.\n",
    "#                 images.append(im)\n",
    "#                 # Flip image.\n",
    "#                 imFlip = cv2.flip(im, 1);\n",
    "#                 # Append flipped image.\n",
    "#                 images.append(imFlip)\n",
    "#     numImages = int(len(images) / 2)\n",
    "#     # Exit if no image found.\n",
    "#     if numImages == 0 :\n",
    "#         print(\"No images found\")\n",
    "#         sys.exit(0)\n",
    "\n",
    "#     print(str(numImages) + \" files read.\")\n",
    "#     return images\n",
    "\n",
    "# # Create data matrix from a list of images.\n",
    "# def createDataMatrix(images):\n",
    "#     print(\"Creating data matrix\", end = \" ... \")\n",
    "#     ''' \n",
    "# \tAllocate space for all images in one data matrix.\n",
    "# \tThe size of the data matrix is\n",
    "# \t( w  * h  * 3, numImages )\n",
    "# \twhere,\n",
    "# \tw = width of an image in the dataset.\n",
    "# \th = height of an image in the dataset.\n",
    "# \t3 is for the 3 color channels.\n",
    "# \t'''\n",
    "#     numImages = len(images)\n",
    "#     sz = images[0].shape\n",
    "#     # Data matrix.\n",
    "#     data = np.zeros((numImages, sz[0] * sz[1] * sz[2]), dtype = np.float32)\n",
    "#     for i in range(0, numImages):\n",
    "#         image = images[i].flatten()\n",
    "#         # Each row get replaced with one flattened image.\n",
    "#         data[i,:] = image\n",
    "\n",
    "#     print(\"DONE\")\n",
    "#     return data\n",
    "\n",
    "# # Generate new face.\n",
    "# def createNewFace(*args):\n",
    "#     # Start with the mean image.\n",
    "#     output = averageFace\n",
    "\n",
    "#     # Add the eigen faces with the weights.\n",
    "#     for i in range(0, NUM_EIGEN_FACES):\n",
    "#         # Get trackbar position.\n",
    "#         '''\n",
    "# \t\tOpenCV does not allow slider values to be negative. \n",
    "# \t\tSo we use weight = sliderValue - MAX_SLIDER_VALUE / 2\n",
    "# \t\t''' \n",
    "#         sliderValues[i] = cv2.getTrackbarPos(\"Weight\" + str(i), \"Trackbars\");\n",
    "#         weight = sliderValues[i] - MAX_SLIDER_VALUE/2\n",
    "#         # Add the weighted eigen face to the mean face.\n",
    "#         output = np.add(output, eigenFaces[i] * weight)\n",
    "\n",
    "#     # Display Result at 2x size.\n",
    "#     output = cv2.resize(output, (0,0), fx = 2, fy = 2)\n",
    "#     cv2.imshow(\"Result\", output)\n",
    "\n",
    "# # Reset sliders callback function.\n",
    "# def resetSliderValues(*args):\n",
    "#     for i in range(0, NUM_EIGEN_FACES):\n",
    "#         cv2.setTrackbarPos(\"Weight\" + str(i), \"Trackbars\", int(MAX_SLIDER_VALUE/2));\n",
    "#     createNewFace()\n",
    "    \n",
    "    \n",
    "# def load_face_dataset(dataset_path):\n",
    "#     faces = []\n",
    "#     labels = []\n",
    "\n",
    "#     # Get a list of subdirectories in the dataset path\n",
    "#     person_dirs = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "\n",
    "#     # Loop through each person's directory and read their face images\n",
    "#     for i, person_dir in enumerate(person_dirs):\n",
    "#         # Get a list of image files in the person's directory\n",
    "#         image_files = [os.path.join(dataset_path, person_dir, f) for f in os.listdir(os.path.join(dataset_path, person_dir)) if os.path.isfile(os.path.join(dataset_path, person_dir, f))]\n",
    "\n",
    "#         # Read each image file and append to the faces list\n",
    "#         for image_file in image_files:\n",
    "#             image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "#             faces.append(image)\n",
    "\n",
    "#         # Append a label for each face image in this person's directory\n",
    "#         labels.extend([i] * len(image_files))\n",
    "\n",
    "#     # Convert the faces and labels lists to numpy arrays\n",
    "#     faces = np.array(faces)\n",
    "#     labels = np.array(labels)\n",
    "\n",
    "#     return faces, labels\n",
    "\n",
    "# # Main function.\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     # Number of EigenFaces.\n",
    "#     NUM_EIGEN_FACES = 15\n",
    "\n",
    "#     # Maximum weight.\n",
    "#     MAX_SLIDER_VALUE = 255\n",
    "\n",
    "#     # Directory containing images.\n",
    "#     dirName = \"images\"\n",
    "\n",
    "#     # Read images.\n",
    "#     images = readImages(dirName)\n",
    "\n",
    "#     # Size of images.\n",
    "#     sz = images[0].shape\n",
    "\n",
    "#     # Create data matrix for PCA.\n",
    "#     data = createDataMatrix(images)\n",
    "\n",
    "#     # Compute the eigenvectors from the stack of images created.\n",
    "#     print(\"Calculating PCA \", end = \"...\")\n",
    "    \n",
    "#     mean, eigenVectors = cv2.PCACompute(data, mean = None, maxComponents = NUM_EIGEN_FACES)\n",
    "    \n",
    "#     print (\"DONE\")\n",
    "\n",
    "#     averageFace = mean.reshape(sz)\n",
    "\n",
    "#     # Create a container to hold eigen faces.\n",
    "#     eigenFaces  = []\n",
    "\n",
    "#     # Reshape eigen vectors to eigen faces.\n",
    "#     for eigenVector in eigenVectors:\n",
    "#         # REshape.\n",
    "#         eigenFace = eigenVector.reshape(sz)\n",
    "#         # Append eigen faces to the container.\n",
    "#         eigenFaces.append(eigenFace)\n",
    "\n",
    "#     # Create window for displaying result.\n",
    "#     cv2.namedWindow(\"Result\", cv2.WINDOW_NORMAL)\n",
    "#     # Create window for displaying mean face.\n",
    "#     cv2.namedWindow(\"Average\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "#     # Upscale by a factor of two.\n",
    "#     output = cv2.resize(averageFace, (0,0), fx = 2, fy = 2)\n",
    "    \n",
    "#     # Display.\n",
    "#     cv2.imshow(\"Result\", output)\n",
    "#     cv2.imshow(\"Average\", averageFace)\n",
    "\n",
    "#     # Create Window for trackbars.\n",
    "#     cv2.namedWindow(\"Trackbars\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "#     # Create a list to contain slider values.\n",
    "#     sliderValues = []\n",
    "\n",
    "#     # Create Trackbars.\n",
    "#     for i in range(0, NUM_EIGEN_FACES):\n",
    "#         sliderValues.append(int(MAX_SLIDER_VALUE/2))\n",
    "#         cv2.createTrackbar( \"Weight\" + str(i), \"Trackbars\", int(MAX_SLIDER_VALUE/2), MAX_SLIDER_VALUE, createNewFace)\n",
    "\n",
    "#     # You can reset the sliders by clicking on the mean image.\n",
    "#     cv2.setMouseCallback(\"Average\", resetSliderValues);\n",
    "\n",
    "#     print('''Usage:\n",
    "#     Change the weights using the sliders.\n",
    "#     Mouse hover on the result window to reset sliders.\n",
    "#     Press q to terminate.''')\n",
    "\n",
    "#     key = cv2.waitKey(0)\n",
    "#     if key == ord('q'):\n",
    "#         cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353624b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8203bc2c",
   "metadata": {},
   "source": [
    "# Attempt at Eigenfaces with Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5f95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# import cv2\n",
    "# import speech_recognition as sr\n",
    "# import os\n",
    "\n",
    "# # Initialize video capture object\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Exit if video not opened.\n",
    "# if not video.isOpened():\n",
    "#     print('Could not open video!')\n",
    "#     sys.exit()\n",
    "    \n",
    "# # Tracker Variables\n",
    "# tracker = None\n",
    "# roi = (0, 0, 0, 0)\n",
    "# # -1 for not tracking, 0 for init tracking, 1 for update tracking\n",
    "# tracking_flag = -1\n",
    "\n",
    "# # Initialize KCF tracker\n",
    "# tracker = cv2.TrackerKCF_create()\n",
    "\n",
    "# # Initialize eigenface classifier\n",
    "# recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "\n",
    "# # Create an empty dictionary to store tracked objects and their names\n",
    "# objects = {}\n",
    "\n",
    "# # Initialize speech recognition object\n",
    "# r = sr.Recognizer()\n",
    "\n",
    "# while True:\n",
    "#     # Read a frame from the video capture object\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     # Check if the frame is read correctly\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # Check if there are any tracked objects\n",
    "#     if len(objects) == 0:\n",
    "#         # Get the user input for the name of the object being tracked\n",
    "#         with sr.Microphone() as source:\n",
    "#             print(\"Please say the name of the object you want to track:\")\n",
    "#             audio = r.listen(source)\n",
    "\n",
    "#         try:\n",
    "#             name = r.recognize_google(audio)\n",
    "#             print(f\"The object being tracked is: {name}\")\n",
    "#         except:\n",
    "#             print(\"Sorry, I could not understand your command.\")\n",
    "#             continue\n",
    "\n",
    "#         # Select the object to be tracked using a bounding box\n",
    "#         bbox = cv2.selectROI(\"Frame\", frame, fromCenter=False, showCrosshair=True)\n",
    "\n",
    "#         # Initialize the tracker with the selected bounding box\n",
    "#         tracker.init(frame, bbox)\n",
    "\n",
    "#         # Store the tracked object and its name in the dictionary\n",
    "#         objects[name] = bbox\n",
    "\n",
    "#     # Loop through all the tracked objects\n",
    "#     for name, bbox in objects.items():\n",
    "#         # Update the tracker with the current frame\n",
    "#         success, bbox = tracker.update(frame)\n",
    "\n",
    "#         # Check if the object is still in the frame\n",
    "#         if success:\n",
    "#             # Draw the bounding box around the tracked object\n",
    "#             (x, y, w, h) = [int(v) for v in bbox]\n",
    "#             cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "#             # Use eigenface classification to recognize the tracked object\n",
    "#             gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#             roi = gray[y:y + h, x:x + w]\n",
    "#             roi = cv2.resize(roi, (100, 100))\n",
    "\n",
    "#             label, confidence = recognizer.predict(roi)\n",
    "\n",
    "#             # Display the name of the tracked object on the bounding box\n",
    "#             cv2.putText(frame, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "#             # If the confidence is low, it means the object is not recognized\n",
    "#             if confidence > 100:\n",
    "#                 cv2.putText(frame, \"Unrecognized\", (x, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "#             else:\n",
    "#                 cv2.putText(frame, f\"{label}\", (x, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "#         else:\n",
    "#             # If the object is not in the frame, remove it from the dictionary\n",
    "#             del objects[name]\n",
    "\n",
    "#     # Display the resulting frame\n",
    "#     cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "#     # Press 'q' to exit the loop\n",
    "#     key = cv2.waitKey(1) & 0xFF\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
